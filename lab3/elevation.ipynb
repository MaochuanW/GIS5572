{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import psycopg2\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import arcpy\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayerCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get raster data from postgis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import rasterio\n",
    "from rasterio.io import MemoryFile\n",
    "import numpy as np\n",
    "from rasterio.features import bounds as feature_bounds\n",
    "\n",
    "# Set up your database connection parameters\n",
    "db_host = \"35.223.186.20\"\n",
    "db_port = \"5432\"\n",
    "db_name = \"postgres\"\n",
    "db_user = \"postgres\"\n",
    "db_password = \"139571wang\"\n",
    "\n",
    "# Connect to the PostgreSQL database\n",
    "conn_string = f\"dbname='{db_name}' user='{db_user}' host='{db_host}' password='{db_password}' port='{db_port}'\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the raster_table and column name\n",
    "raster_table = \"raster_table\"\n",
    "raster_column = \"rast\"\n",
    "\n",
    "# Fetch the raw raster data from the PostGIS database\n",
    "cursor.execute(f\"SELECT ST_AsBinary({raster_column}) FROM {raster_table};\")\n",
    "raster_data = cursor.fetchone()\n",
    "\n",
    "if raster_data:\n",
    "    # Read the binary raster data using rasterio\n",
    "    with MemoryFile(raster_data[0]) as memfile:\n",
    "        with memfile.open() as dataset:\n",
    "            # Get raster data and metadata\n",
    "            profile = dataset.profile\n",
    "            data = dataset.read()\n",
    "\n",
    "            # Define the output path and save the raster data to a file\n",
    "            raster_output_path = r\"C:/test/DEM_raster.tif\"\n",
    "            with rasterio.open(raster_output_path, \"w\", **profile) as dest:\n",
    "                dest.write(data)\n",
    "\n",
    "else:\n",
    "    print(\"No raster data found in the table.\")\n",
    "\n",
    "# Close the database connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smple 0.00365% of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.management.Resample(r\"C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\DEM.tif\", r\"C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\resampled_dem.tif\", \"5000 5000\", \"NEAREST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert raster into point shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.conversion.RasterToPoint(\"resampled_dem.tif\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\RasterT_resampl1\", \"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDW interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_raster = arcpy.sa.Idw(\"RasterT_DEM_Res1\", \"grid_code\", 500, 2, \"VARIABLE 12\", None); out_raster.save(r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\Idw_RasterT_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kriging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_surface_raster = arcpy.sa.Kriging(\"RasterT_DEM_Res2\", \"grid_code\", \"Spherical # # # #\", 2220, \"VARIABLE 100\", None); out_surface_raster.save(r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\Kriging_Rast2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.ga.RadialBasisFunctions(\"RasterT_DEM_Res2\", \"grid_code\", None, r\"C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\RBF_DEM.tif\", 2220, \"NBRTYPE=Standard S_MAJOR=213676.888081046 S_MINOR=213676.888081046 ANGLE=0 NBR_MAX=15 NBR_MIN=10 SECTOR_TYPE=ONE_SECTOR\", \"COMPLETELY_REGULARIZED_SPLINE\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.ga.CrossValidation(\"idw_table.lyr\", r\"C:\\test\\IDW_ele_CV.shp\")\n",
    "arcpy.ga.CrossValidation(\"krig_table.lyr\", r\"C:\\test\\Kriging_ele_CV.shp\")\n",
    "arcpy.ga.CrossValidation(\"rbf_table.lyr\", r\"C:\\test\\rbf_ele_CV.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE for IDW is: 12.495551541225144\n",
      "The RMSE for Kriging is: 8.8461041415266\n",
      "The RMSE for RBF is: 9.600473079176721\n"
     ]
    }
   ],
   "source": [
    "# Convert attribute table to a NumPy array and pd DataFrame\n",
    "idw_cv_array = arcpy.da.FeatureClassToNumPyArray(r\"C:\\test\\IDW_ele_CV.shp\", [\"FID\", \"Error\"])\n",
    "idw_cv_pd = pd.DataFrame(idw_cv_array, columns=[\"FID\", \"Error\"])\n",
    "\n",
    "Kriging_cv_array = arcpy.da.FeatureClassToNumPyArray(r\"C:\\test\\Kriging_ele_cv.shp\", [\"FID\", \"Error\"])\n",
    "Kriging_cv_pd = pd.DataFrame(Kriging_cv_array, columns=[\"FID\", \"Error\"])\n",
    "\n",
    "RBF_cv_array = arcpy.da.FeatureClassToNumPyArray(r\"C:\\test\\RBF_ele_cv.shp\", [\"FID\", \"Error\"])\n",
    "RBF_cv_pd = pd.DataFrame(RBF_cv_array, columns=[\"FID\", \"Error\"])\n",
    "\n",
    "# Calculate squared error\n",
    "idw_cv_pd['squared_error'] = idw_cv_pd['Error'] ** 2\n",
    "Kriging_cv_pd['squared_error'] = Kriging_cv_pd['Error'] ** 2\n",
    "RBF_cv_pd['squared_error'] = RBF_cv_pd['Error'] ** 2\n",
    "\n",
    "# Calculate RMSE\n",
    "idw_rmse_ele = numpy.sqrt(idw_cv_pd['squared_error'].mean())\n",
    "Kriging_rmse_ele = numpy.sqrt(Kriging_cv_pd['squared_error'].mean())\n",
    "RBF_rmse_ele = numpy.sqrt(RBF_cv_pd['squared_error'].mean())\n",
    "\n",
    "#Print and compare results\n",
    "print(f'The RMSE for IDW is: {idw_rmse}')\n",
    "print(f'The RMSE for Kriging is: {Kriging_rmse}')\n",
    "print(f'The RMSE for RBF is: {RBF_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the PostgreSQL connection\n",
    "connection = psycopg2.connect(host = '35.223.186.20',\n",
    "                             database = 'postgres',\n",
    "                             user = 'postgres',\n",
    "                             password = '139571wang')\n",
    "\n",
    "# Set the name of the new table in the PostgreSQL database\n",
    "output_table = \"elevation_assesment_table\"\n",
    "\n",
    "# Use psycopg2 to create the table in the PostgreSQL database\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(f\"CREATE TABLE {output_table} (method text, rmse double precision)\")\n",
    "\n",
    "# Use psycopg2 to copy the data from the Geodatabase table to the PostgreSQL table\n",
    "cursor.execute(f\"INSERT INTO {output_table} (method, rmse) VALUES (%s, %s)\", ('IDW',idw_rmse_ele))\n",
    "cursor.execute(f\"INSERT INTO {output_table} (method, rmse) VALUES (%s, %s)\", ('Kriging',Kriging_rmse_ele))\n",
    "cursor.execute(f\"INSERT INTO {output_table} (method, rmse) VALUES (%s, %s)\", ('RBF',RBF_rmse_ele))\n",
    "\n",
    "\n",
    "# Commit the changes to the PostgreSQL database\n",
    "connection.commit()\n",
    "\n",
    "# Close the PostgreSQL connection and cursor\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation assessment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kriging: MAE = 4452.514209683938, MSE = 49080492.96334203, RMSE = 7005.747138124672\n",
      "idw: MAE = 4464.159534874823, MSE = 49468383.16601199, RMSE = 7033.376370279923\n",
      "rbf: MAE = 4451.475144462773, MSE = 49198854.4187933, RMSE = 7014.189505480537\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import numpy as np\n",
    "from arcpy.sa import *\n",
    "\n",
    "# 1. Convert the true DEM and the interpolated rasters to point datasets\n",
    "arcpy.conversion.RasterToPoint(\"resampled_dem1.tif\", \"true_dem_points.shp\")\n",
    "arcpy.conversion.RasterToPoint(\"kriging.tif\", \"kriging_points.shp\")\n",
    "arcpy.conversion.RasterToPoint(\"idw.tif\", \"idw_points.shp\")\n",
    "arcpy.conversion.RasterToPoint(\"rbf.tif\", \"rbf_points.shp\")\n",
    "\n",
    "# 2. Sample the true DEM point dataset at the same locations as the interpolated point datasets\n",
    "arcpy.sa.ExtractValuesToPoints(\"kriging_points.shp\", \"resampled_dem1.tif\", \"kriging_points_with_true_elevation.shp\")\n",
    "arcpy.sa.ExtractValuesToPoints(\"idw_points.shp\", \"resampled_dem1.tif\", \"idw_points_with_true_elevation.shp\")\n",
    "arcpy.sa.ExtractValuesToPoints(\"rbf_points.shp\", \"resampled_dem1.tif\", \"rbf_points_with_true_elevation.shp\")\n",
    "\n",
    "# Function to calculate error metrics\n",
    "def calculate_errors(true_elevations, interpolated_elevations):\n",
    "    n = len(true_elevations)\n",
    "    mae = sum(abs(true - pred) for true, pred in zip(true_elevations, interpolated_elevations)) / n\n",
    "    mse = sum((true - pred) ** 2 for true, pred in zip(true_elevations, interpolated_elevations)) / n\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mae, mse, rmse\n",
    "\n",
    "# 3. Calculate error metrics (MAE, MSE, RMSE) for each interpolated point dataset\n",
    "datasets = [\"kriging\", \"idw\", \"rbf\"]\n",
    "\n",
    "for dataset in datasets:\n",
    "    input_shapefile = f\"{dataset}_points_with_true_elevation.shp\"\n",
    "    true_elevations = []\n",
    "    interpolated_elevations = []\n",
    "\n",
    "    with arcpy.da.SearchCursor(input_shapefile, [\"RASTERVALU\", \"GRID_CODE\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            true_elevations.append(row[0])\n",
    "            interpolated_elevations.append(row[1])\n",
    "\n",
    "    mae, mse, rmse = calculate_errors(true_elevations, interpolated_elevations)\n",
    "    print(f\"{dataset}: MAE = {mae}, MSE = {mse}, RMSE = {rmse}\")\n",
    "\n",
    "\n",
    "# Insert the error metrics for each interpolation method\n",
    "for dataset in datasets:\n",
    "    # 5. Create a point layer showing the differences between the ground truth and model predictions\n",
    "    output_shapefile = f\"{dataset}_differences.shp\"\n",
    "    arcpy.management.Copy(input_shapefile, output_shapefile)\n",
    "\n",
    "    arcpy.management.AddField(output_shapefile, \"difference\", \"DOUBLE\")\n",
    "    with arcpy.da.UpdateCursor(output_shapefile, [\"RASTERVALU\", \"GRID_CODE\", \"difference\"]) as cursor:\n",
    "        for row in cursor:\n",
    "            true_elevation = row[0]\n",
    "            interpolated_elevation = row[1]\n",
    "            difference = true_elevation - interpolated_elevation\n",
    "            row[2] = difference\n",
    "            cursor.updateRow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clip to the extent of Minnesota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.analysis.Clip(\"kriging_difference\", r\"BOUNDARIES OF MINNESOTA\\STATE\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\kriging_difference_Clip\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.analysis.Clip(\"idw_differences\", r\"BOUNDARIES OF MINNESOTA\\STATE\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\idw_difference_Clip\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.analysis.Clip(\"rbf_differences\", r\"BOUNDARIES OF MINNESOTA\\STATE\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\rbf_difference_Clip\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload kriging to postgis database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 6, 2023 9:08:30 PM\",\"Succeeded at Thursday, April 6, 2023 9:08:31 PM (Elapsed Time: 0.97 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Maochuan\\\\OneDrive\\\\文档\\\\ArcGIS\\\\Projects\\\\arc2_lab3\\\\arc2_lab3.gdb\\\\Int_rbf1'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.ddd.Int(\"rbf.tif\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\Int_kriging1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 6, 2023 9:09:11 PM\",\"Succeeded at Thursday, April 6, 2023 9:09:13 PM (Elapsed Time: 2.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Maochuan\\\\OneDrive\\\\文档\\\\ArcGIS\\\\Projects\\\\arc2_lab3\\\\arc2_lab3.gdb\\\\RasterT_Int_rbf1'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.conversion.RasterToPolygon(r\"New Group Layer\\Int_kriging1\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\RasterT_Int_kri2\", \"SIMPLIFY\", \"Value\", \"MULTIPLE_OUTER_PART\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPROJECT  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, April 6, 2023 11:17:33 PM\",\"Succeeded at Thursday, April 6, 2023 11:17:38 PM (Elapsed Time: 4.49 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Maochuan\\\\OneDrive\\\\文档\\\\ArcGIS\\\\Projects\\\\arc2_lab3\\\\arc2_lab3.gdb\\\\rbf_poly_Project'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Project(\"RasterT_Int_kri2\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\RasterT_Int_kri2_Project\", 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \"WGS_1984_(ITRF00)_To_NAD_1983\", 'PROJCS[\"NAD_1983_UTM_Zone_15N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-93.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]', \"NO_PRESERVE_SHAPE\", None, \"NO_VERTICAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload using shp2pgsql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code: 0\n",
      "Error message: could not print result table: Invalid argument\n",
      "Field id is an FTDouble with width 10 and precision 0\n",
      "Field gridcode is an FTDouble with width 10 and precision 0\n",
      "Field shape_leng is an FTDouble with width 19 and precision 11\n",
      "Field shape_le_1 is an FTDouble with width 19 and precision 11\n",
      "Field shape_area is an FTDouble with width 19 and precision 11\n",
      "Shapefile type: Polygon\n",
      "Postgis type: MULTIPOLYGON[2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Set the necessary parameters\n",
    "shp2pgsql_path = r\"C:\\Program Files\\PostgreSQL\\15\\bin\\shp2pgsql.exe\"\n",
    "psql_path = r\"C:\\Program Files\\PostgreSQL\\15\\bin\\psql.exe\"\n",
    "shapefile_path = r\"C:\\test\\kriging_elevation_finall.shp\"\n",
    "srid = 4326\n",
    "schema_table = \"public.kriging_elevationn\"\n",
    "host = \"35.223.186.20\"\n",
    "port = 5432\n",
    "user = \"postgres\"\n",
    "db_name = \"postgres\"\n",
    "password = \"139571wang\"\n",
    "\n",
    "# Build the shp2pgsql command\n",
    "shp2pgsql_command = f\"\\\"{shp2pgsql_path}\\\" -s {srid} {shapefile_path} {schema_table}\"\n",
    "\n",
    "# Build the psql command\n",
    "psql_command = f\"\\\"{psql_path}\\\" -h {host} -p {port} -U {user} -d {db_name} -w\"\n",
    "\n",
    "# Combine the commands using a pipe\n",
    "full_command = f\"{shp2pgsql_command} | {psql_command}\"\n",
    "\n",
    "# Set up the environment with the password\n",
    "env = os.environ.copy()\n",
    "env[\"PGPASSWORD\"] = password\n",
    "\n",
    "# Run the command using the subprocess module and capture stderr\n",
    "process = subprocess.Popen(full_command, shell=True, env=env, stderr=subprocess.PIPE)\n",
    "\n",
    "# Wait for the process to finish and capture the return code and stderr\n",
    "return_code = process.wait()\n",
    "stderr_output = process.stderr.read().decode()\n",
    "\n",
    "# Print the return code and error message\n",
    "print(f\"Return code: {return_code}\")\n",
    "print(f\"Error message: {stderr_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from flask import Flask, jsonify\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/kriging_elevation', methods=['GET'])\n",
    "def get_polygon():\n",
    "    conn = psycopg2.connect(host='35.223.186.20',\n",
    "                            database='postgres',\n",
    "                            user='postgres',\n",
    "                            password='139571wang')\n",
    "\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    cur.execute(sql.(\"SELECT gridcode, ST_AsGeoJSON(geom)::json AS geometry FROM kriging_elevation\"))\n",
    "    result = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download geojson from url using flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file path: C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_elevation.geojson\n",
      "GeoJSON file saved as C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_elevation.geojson\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Replace this URL with the address of your Flask application\n",
    "url = \"http://34.27.164.176:5000/kriging_elevation\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    geojson_data = response.json()\n",
    "\n",
    "    # Save the GeoJSON to the specified folder and name it \"lab3_test.geojson\"\n",
    "    output_folder = r\"C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\"\n",
    "    output_file_path = os.path.join(output_folder, \"kriging_elevation.geojson\")\n",
    "    print(f\"Output file path: {output_file_path}\")\n",
    "\n",
    "    with open(output_file_path, \"w\") as f:\n",
    "        json.dump(geojson_data, f)\n",
    "    print(f\"GeoJSON file saved as {output_file_path}\")\n",
    "else:\n",
    "    print(\"Error fetching GeoJSON data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert geojson into esri geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read input JSON data from file\n",
    "with open(r'C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_elevation.geojson', 'r') as input_file:\n",
    "    input_data = json.load(input_file)\n",
    "\n",
    "# Process input data and create output data\n",
    "output_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": [\n",
    "        {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"MultiPolygon\",\n",
    "                \"coordinates\": polygon_data[\"geometry\"][\"coordinates\"]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"elevation\": polygon_data[\"gridcode\"]\n",
    "            }\n",
    "        }\n",
    "        for polygon_data in input_data\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Write output JSON data to file\n",
    "with open(r'C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_elevation_final.json', 'w') as output_file:\n",
    "    json.dump(output_data, output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json to feature class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, April 12, 2023 11:45:34 PM\",\"Succeeded at Wednesday, April 12, 2023 11:45:46 PM (Elapsed Time: 11.76 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\test\\\\kriging_elevation_final.shp'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.conversion.JSONToFeatures(r\"C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_elevation_final.json\", r\"C:\\test\\kriging_elevation_final.shp\", \"POLYGON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload feature class to arconline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "\n",
    "# Function to zip shapefile\n",
    "def zip_shapefile(shapefile_path):\n",
    "    with zipfile.ZipFile(shapefile_path + '.zip', 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "        for file_name in os.listdir(os.path.dirname(shapefile_path)):\n",
    "            if file_name.startswith(os.path.basename(shapefile_path).split('.')[0]) and not file_name.endswith('.zip'):\n",
    "                zf.write(os.path.join(os.path.dirname(shapefile_path), file_name), arcname=file_name)\n",
    "\n",
    "# Connect to your ArcGIS Online organization\n",
    "gis = GIS(\"home\")\n",
    "\n",
    "# Set the input shapefile path\n",
    "input_shapefile = r'C:\\test\\kriging_elevation_final.shp'\n",
    "\n",
    "# Zip the shapefile\n",
    "zip_shapefile(input_shapefile)\n",
    "\n",
    "# Upload the zipped shapefile as a new item\n",
    "item = gis.content.add({'type': 'Shapefile'}, input_shapefile + '.zip')\n",
    "\n",
    "# Publish the new item as a feature layer\n",
    "feature_layer_item = item.publish()\n",
    "\n",
    "# Get the feature layer URL and print it\n",
    "feature_layer_url = feature_layer_item.url\n",
    "print(feature_layer_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# upload kriging_difference point accuracy assesment layer to postgis database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, April 12, 2023 7:16:07 PM\",\"Succeeded at Wednesday, April 12, 2023 7:16:10 PM (Elapsed Time: 3.71 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Maochuan\\\\OneDrive\\\\文档\\\\ArcGIS\\\\Projects\\\\arc2_lab3\\\\arc2_lab3.gdb\\\\kriging_difference_C_Project'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Project(\"kriging_difference_Clip\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\kriging_difference_C_Project\", 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \"WGS_1984_(ITRF00)_To_NAD_1983\", 'PROJCS[\"NAD_1983_UTM_Zone_15N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-93.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]', \"NO_PRESERVE_SHAPE\", None, \"NO_VERTICAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return code: 0\n",
      "Error message: could not print result table: Invalid argument\n",
      "Field pointid is an FTDouble with width 10 and precision 0\n",
      "Field grid_code is an FTDouble with width 13 and precision 11\n",
      "Field rastervalu is an FTDouble with width 10 and precision 0\n",
      "Field difference is an FTDouble with width 19 and precision 11\n",
      "Shapefile type: Point\n",
      "Postgis type: POINT[2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Set the necessary parameters\n",
    "shp2pgsql_path = r\"C:\\Program Files\\PostgreSQL\\15\\bin\\shp2pgsql.exe\"\n",
    "psql_path = r\"C:\\Program Files\\PostgreSQL\\15\\bin\\psql.exe\"\n",
    "shapefile_path = r\"C:\\test\\Kriging_difference_reprojected.shp\"\n",
    "srid = 4326\n",
    "schema_table = \"public.Kriging_Difference\"\n",
    "host = \"35.223.186.20\"\n",
    "port = 5432\n",
    "user = \"postgres\"\n",
    "db_name = \"postgres\"\n",
    "password = \"139571wang\"\n",
    "\n",
    "# Build the shp2pgsql command\n",
    "shp2pgsql_command = f\"\\\"{shp2pgsql_path}\\\" -s {srid} {shapefile_path} {schema_table}\"\n",
    "\n",
    "# Build the psql command\n",
    "psql_command = f\"\\\"{psql_path}\\\" -h {host} -p {port} -U {user} -d {db_name} -w\"\n",
    "\n",
    "# Combine the commands using a pipe\n",
    "full_command = f\"{shp2pgsql_command} | {psql_command}\"\n",
    "\n",
    "# Set up the environment with the password\n",
    "env = os.environ.copy()\n",
    "env[\"PGPASSWORD\"] = password\n",
    "\n",
    "# Run the command using the subprocess module and capture stderr\n",
    "process = subprocess.Popen(full_command, shell=True, env=env, stderr=subprocess.PIPE)\n",
    "\n",
    "# Wait for the process to finish and capture the return code and stderr\n",
    "return_code = process.wait()\n",
    "stderr_output = process.stderr.read().decode()\n",
    "\n",
    "# Print the return code and error message\n",
    "print(f\"Return code: {return_code}\")\n",
    "print(f\"Error message: {stderr_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from flask import Flask, jsonify\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/kriging_difference', methods=['GET'])\n",
    "def get_polygon():\n",
    "    conn = psycopg2.connect(host='35.223.186.20',\n",
    "                            database='postgres',\n",
    "                            user='postgres',\n",
    "                            password='139571wang')\n",
    "\n",
    "    cur = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    # Cast \"difference\" to double precision in the SQL query\n",
    "    cur.execute(sql.SQL(\"SELECT difference::double precision, ST_AsGeoJSON(geom)::json AS geometry FROM kriging_difference\"))\n",
    "    result = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file path: C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_difference.geojson\n",
      "GeoJSON file saved as C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_difference.geojson\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Replace this URL with the address of your Flask application\n",
    "url = \"http://34.27.164.176:5000/kriging_difference\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    geojson_data = response.json()\n",
    "\n",
    "    # Save the GeoJSON to the specified folder and name it \"lab3_test.geojson\"\n",
    "    output_folder = r\"C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\"\n",
    "    output_file_path = os.path.join(output_folder, \"kriging_difference.geojson\")\n",
    "    print(f\"Output file path: {output_file_path}\")\n",
    "\n",
    "    with open(output_file_path, \"w\") as f:\n",
    "        json.dump(geojson_data, f)\n",
    "    print(f\"GeoJSON file saved as {output_file_path}\")\n",
    "else:\n",
    "    print(\"Error fetching GeoJSON data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Read input JSON data from file\n",
    "with open(r'C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_difference.geojson', 'r') as input_file:\n",
    "    input_data = json.load(input_file)\n",
    "\n",
    "# Process input data and create output data\n",
    "output_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": [\n",
    "        {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": point_data[\"geometry\"][\"coordinates\"]\n",
    "            },\n",
    "            \"properties\": {\n",
    "                \"difference\": point_data[\"difference\"]\n",
    "            }\n",
    "        }\n",
    "        for point_data in input_data\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Write output JSON data to file\n",
    "with open(r'C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_difference_esri.geojson', 'w') as output_file:\n",
    "    json.dump(output_data, output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, April 12, 2023 7:58:33 PM\",\"Succeeded at Wednesday, April 12, 2023 7:58:38 PM (Elapsed Time: 5.25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\Maochuan\\\\OneDrive\\\\文档\\\\ArcGIS\\\\Projects\\\\arc2_lab3\\\\arc2_lab3.gdb\\\\kriging_differ_JSONToFeature'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.conversion.JSONToFeatures(r\"C:\\Users\\Maochuan\\OneDrive\\桌面\\lab3\\kriging_difference_esri.geojson\", r\"C:\\Users\\Maochuan\\OneDrive\\文档\\ArcGIS\\Projects\\arc2_lab3\\arc2_lab3.gdb\\kriging_differ_JSONToFeature\", \"POINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayerCollection\n",
    "\n",
    "# Function to zip shapefile\n",
    "def zip_shapefile(shapefile_path):\n",
    "    with zipfile.ZipFile(shapefile_path + '.zip', 'w', zipfile.ZIP_DEFLATED) as zf:\n",
    "        for file_name in os.listdir(os.path.dirname(shapefile_path)):\n",
    "            if file_name.startswith(os.path.basename(shapefile_path).split('.')[0]) and not file_name.endswith('.zip'):\n",
    "                zf.write(os.path.join(os.path.dirname(shapefile_path), file_name), arcname=file_name)\n",
    "\n",
    "# Connect to your ArcGIS Online organization\n",
    "gis = GIS(\"home\")\n",
    "\n",
    "# Set the input shapefile path\n",
    "input_shapefile = r'C:\\test\\Kriging_difference_final.shp'\n",
    "\n",
    "# Zip the shapefile\n",
    "zip_shapefile(input_shapefile)\n",
    "\n",
    "# Upload the zipped shapefile as a new item\n",
    "item = gis.content.add({'type': 'Shapefile'}, input_shapefile + '.zip')\n",
    "\n",
    "# Publish the new item as a feature layer\n",
    "feature_layer_item = item.publish()\n",
    "\n",
    "# Get the feature layer URL and print it\n",
    "feature_layer_url = feature_layer_item.url\n",
    "print(feature_layer_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export FLASK_APP=app.py\n",
    "flask run --host=0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
